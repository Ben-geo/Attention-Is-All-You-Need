# Attention-Is-All-You-Need

This is a reproduction of 2017 paper attention is all you need

Let's start with the need for Transformer; a model that only used the attention and removed the need for recurrance or convultions for sequential data

Limitations of Recurrance and Convulutions
Recurrance
* Lack of Parallelizaion
    